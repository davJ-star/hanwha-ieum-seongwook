{
    "sourceFile": "ai/llama/client.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1737028563537,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1737028563537,
            "name": "Commit-0",
            "content": "import requests\r\n\r\ndef send_prompt(prompt):\r\n    url = \"http://127.0.0.1:8000/generate\"\r\n    data = {\"prompt\": prompt}\r\n    try:\r\n        response = requests.post(url, json=data)\r\n        response.raise_for_status()\r\n        return response.json()\r\n    except requests.RequestException as e:\r\n        print(f\"오류 발생: {e}\")\r\n        if hasattr(e.response, 'text'):\r\n            print(\"서버 응답:\", e.response.text)\r\n        return None\r\n\r\nif __name__ == \"__main__\":\r\n    prompt = input(\"프롬프트를 입력하세요: \")\r\n    result = send_prompt(prompt)\r\n    if result and 'generated_text' in result:\r\n        print(\"생성된 텍스트:\", result[\"generated_text\"])\r\n    else:\r\n        print(\"텍스트 생성에 실패했습니다.\")\r\n"
        }
    ]
}