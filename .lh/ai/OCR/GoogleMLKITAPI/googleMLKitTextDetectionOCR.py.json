{
    "sourceFile": "ai/OCR/GoogleMLKITAPI/googleMLKitTextDetectionOCR.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1737102497402,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1737102638511,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,5 +21,5 @@\n     if response.error.message:\r\n         raise Exception(f'{response.error.message}\\n자세한 오류 정보: https://cloud.google.com/apis/design/errors')\r\n \r\n # 이미지 파일 경로를 지정하여 함수 호출\r\n-detect_text('path/to/your/image.jpg')\r\n+detect_text('C:\\\\Users\\\\82106\\\\develop\\\\hanwha-ieum\\\\ai\\\\img\\\\test.jpg')\r\n"
                },
                {
                    "date": 1737103089356,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,25 +1,40 @@\n-from google.cloud import vision\r\n-import io\r\n+from langchain_community.llms import HuggingFacePipeline\r\n+from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\r\n+import torch\r\n+import warnings\r\n \r\n-def detect_text(path):\r\n-    \"\"\"이미지 파일에서 텍스트를 감지합니다.\"\"\"\r\n-    client = vision.ImageAnnotatorClient()\r\n+# 경고 무시 설정\r\n+warnings.filterwarnings(\"ignore\", category=UserWarning)\r\n \r\n-    with io.open(path, 'rb') as image_file:\r\n-        content = image_file.read()\r\n+def load_eeve_model():\r\n+    model_name = \"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\"\r\n+    tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n+    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\r\n+    \r\n+    pipe = pipeline(\r\n+        \"text-generation\",\r\n+        model=model,\r\n+        tokenizer=tokenizer,\r\n+        max_new_tokens=512,\r\n+        do_sample=True,  # 샘플링 활성화\r\n+        temperature=0.7,\r\n+        top_p=0.95,\r\n+        repetition_penalty=1.15\r\n+    )\r\n+    \r\n+    local_llm = HuggingFacePipeline(pipeline=pipe)\r\n+    return local_llm\r\n \r\n-    image = vision.Image(content=content)\r\n-    response = client.text_detection(image=image)\r\n-    texts = response.text_annotations\r\n+def chat_with_eeve(llm):\r\n+    print(\"EEVE-Korean 챗봇에 오신 것을 환영합니다! (종료하려면 'quit'를 입력하세요)\")\r\n+    while True:\r\n+        user_input = input(\"사용자: \")\r\n+        if user_input.lower() == 'quit':\r\n+            break\r\n+        \r\n+        response = llm.invoke(user_input)  # __call__ 대신 invoke 사용\r\n+        print(\"EEVE:\", response)\r\n \r\n-    print('텍스트:')\r\n-    for text in texts:\r\n-        print(f'\\n\"{text.description}\"')\r\n-        vertices = [f'({vertex.x},{vertex.y})' for vertex in text.bounding_poly.vertices]\r\n-        print('경계: {}'.format(','.join(vertices)))\r\n-\r\n-    if response.error.message:\r\n-        raise Exception(f'{response.error.message}\\n자세한 오류 정보: https://cloud.google.com/apis/design/errors')\r\n-\r\n-# 이미지 파일 경로를 지정하여 함수 호출\r\n-detect_text('C:\\\\Users\\\\82106\\\\develop\\\\hanwha-ieum\\\\ai\\\\img\\\\test.jpg')\r\n+if __name__ == \"__main__\":\r\n+    eeve_model = load_eeve_model()\r\n+    chat_with_eeve(eeve_model)\r\n"
                }
            ],
            "date": 1737102497402,
            "name": "Commit-0",
            "content": "from google.cloud import vision\r\nimport io\r\n\r\ndef detect_text(path):\r\n    \"\"\"이미지 파일에서 텍스트를 감지합니다.\"\"\"\r\n    client = vision.ImageAnnotatorClient()\r\n\r\n    with io.open(path, 'rb') as image_file:\r\n        content = image_file.read()\r\n\r\n    image = vision.Image(content=content)\r\n    response = client.text_detection(image=image)\r\n    texts = response.text_annotations\r\n\r\n    print('텍스트:')\r\n    for text in texts:\r\n        print(f'\\n\"{text.description}\"')\r\n        vertices = [f'({vertex.x},{vertex.y})' for vertex in text.bounding_poly.vertices]\r\n        print('경계: {}'.format(','.join(vertices)))\r\n\r\n    if response.error.message:\r\n        raise Exception(f'{response.error.message}\\n자세한 오류 정보: https://cloud.google.com/apis/design/errors')\r\n\r\n# 이미지 파일 경로를 지정하여 함수 호출\r\ndetect_text('path/to/your/image.jpg')\r\n"
        }
    ]
}