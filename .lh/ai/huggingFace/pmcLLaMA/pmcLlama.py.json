{
    "sourceFile": "ai/huggingFace/pmcLLaMA/pmcLlama.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1737265848456,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1737266445471,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,1 +1,2 @@\n-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\n\\ No newline at end of file\n+from huggingface_hub import login\r\n+login()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1737266465071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,2 +1,4 @@\n from huggingface_hub import login\r\n-login()\n\\ No newline at end of file\n+login()\r\n+\r\n+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\n\\ No newline at end of file\n"
                },
                {
                    "date": 1737266921915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,3 @@\n from huggingface_hub import login\r\n login()\r\n \r\n-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\n\\ No newline at end of file\n"
                },
                {
                    "date": 1737266936726,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,3 +0,0 @@\n-from huggingface_hub import login\r\n-login()\r\n-\r\n\\ No newline at end of file\n"
                },
                {
                    "date": 1737267221413,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,1 +1,5 @@\n-\n+from transformers import LlamaTokenizer, LlamaForCausalLM\r\n+\r\n+model_name = \"chaoyi-wu/PMC_LLAMA_7B\"\r\n+tokenizer = LlamaTokenizer.from_pretrained(model_name)\r\n+model = LlamaForCausalLM.from_pretrained(model_name)\r\n"
                },
                {
                    "date": 1737267233272,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,4 +2,27 @@\n \r\n model_name = \"chaoyi-wu/PMC_LLAMA_7B\"\r\n tokenizer = LlamaTokenizer.from_pretrained(model_name)\r\n model = LlamaForCausalLM.from_pretrained(model_name)\r\n+\r\n+import torch\r\n+\r\n+def generate_text(prompt, max_length=200):\r\n+    inputs = tokenizer(prompt, return_tensors=\"pt\")\r\n+    \r\n+    with torch.no_grad():\r\n+        generated = model.generate(\r\n+            inputs[\"input_ids\"],\r\n+            max_length=max_length,\r\n+            num_return_sequences=1,\r\n+            do_sample=True,\r\n+            top_k=50,\r\n+            top_p=0.95,\r\n+            temperature=0.7\r\n+        )\r\n+    \r\n+    return tokenizer.decode(generated[0], skip_special_tokens=True)\r\n+\r\n+# 예시 사용\r\n+prompt = \"The role of antibiotics in treating bacterial infections is\"\r\n+generated_text = generate_text(prompt)\r\n+print(generated_text)\r\n"
                },
                {
                    "date": 1737267246348,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,12 +1,12 @@\n from transformers import LlamaTokenizer, LlamaForCausalLM\r\n+import torch\r\n \r\n+# 모델 및 토크나이저 로드\r\n model_name = \"chaoyi-wu/PMC_LLAMA_7B\"\r\n tokenizer = LlamaTokenizer.from_pretrained(model_name)\r\n model = LlamaForCausalLM.from_pretrained(model_name)\r\n \r\n-import torch\r\n-\r\n def generate_text(prompt, max_length=200):\r\n     inputs = tokenizer(prompt, return_tensors=\"pt\")\r\n     \r\n     with torch.no_grad():\r\n"
                }
            ],
            "date": 1737265848456,
            "name": "Commit-0",
            "content": "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"
        }
    ]
}