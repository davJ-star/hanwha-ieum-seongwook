from typing import Optional, List
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI
import os, uuid, time, json, requests

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)


# ê¸°ë³¸ ìš”ì²­ ëª¨ë¸
class MedicalRequest(BaseModel):
    page_type: str
    situation: str
    original_info: str
    target_age: int


# ìƒì„¸ ìš”ì²­ ëª¨ë¸
class DetailedMedicalRequest(BaseModel):
    category: str
    page_type: str
    situation: str
    original_info: str
    target_age: int


# ì•½í’ˆ ê²€ìƒ‰ ìš”ì²­ ëª¨ë¸
class DrugSearchRequest(BaseModel):
    query: str
    ocr_words: Optional[List[str]] = None

    class Config:
        json_schema_extra = {
            "example": {
                "query": "íƒ€ì´ë ˆë†€",
                "ocr_words": ["íƒ€ì´ë ˆë†€", "ì§„í†µ", "í•´ì—´"]
            }
        }


# OCR ì—”ë“œí¬ì¸íŠ¸
@app.post("/ocr")
async def ocr_endpoint(file: UploadFile = File(...)):
    try:
        load_dotenv()
        api_url = os.getenv('CLOVA_OCR_API_URL')
        secret_key = os.getenv('CLOVA_OCR_API_SECRET_KEY').strip()

        request_json = {
            'images': [{'format': file.filename.split('.')[-1], 'name': 'demo'}],
            'requestId': str(uuid.uuid4()),
            'version': 'V2',
            'timestamp': int(round(time.time() * 1000))
        }

        payload = {'message': json.dumps(request_json).encode('UTF-8')}
        files = [('file', await file.read())]
        headers = {'X-OCR-SECRET': secret_key}

        response = requests.request("POST", api_url, headers=headers, data=payload, files=files)
        result = response.json()

        text = ""
        for field in result['images'][0]['fields']:
            text += field['inferText'] + " "

        return {"text": text.strip()}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ê¸°ë³¸ ê°„ë‹¨í™” ì—”ë“œí¬ì¸íŠ¸
@app.post("/simplify")
async def simplify_endpoint(request: MedicalRequest):
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        ë‹¹ì‹ ì€ ë³µì¡í•œ ì˜í•™ ì •ë³´ë¥¼ ëˆ„êµ¬ë‚˜ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        í˜„ì¬ ìƒí™©: {request.situation}
        í˜ì´ì§€ ìœ í˜•: {request.page_type}
        ëŒ€ìƒ ì—°ë ¹: {request.target_age}ì„¸

        ë‹¤ìŒì˜ ì˜í•™ ì •ë³´ë¥¼ {request.target_age}ì„¸ ì–´ë¦°ì´ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¤ì‹œ ì¡´ëŒ“ë§ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:

        {request.original_info}

        ì„¤ëª…í•  ë•Œ ë‹¤ìŒ ì‚¬í•­ì„ ì§€ì¼œì£¼ì„¸ìš”:
        1. {request.target_age}ì„¸ ì–´ë¦°ì´ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´ì™€ ê°œë…ì„ ì‚¬ìš©í•˜ì„¸ìš”.
        2. ì§§ê³  ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
        3. ì–´ë µê³ , ë³µì¡í•œ ì˜í•™ ìš©ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        4. í’ì„ ì´ë‚˜ ì¼ìƒì ì¸ ë¬¼ê±´ì„ í™œìš©í•œ ë¹„ìœ ë¥¼ ì‚¬ìš©í•´ ì„¤ëª…í•˜ì„¸ìš”.
        5. ì „ì²´ ì„¤ëª…ì„ 3-4ê°œì˜ ì§§ì€ ë‹¨ë½ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”.
        6. ì–´ë¦°ì´ê°€ ë¬´ì„œì›Œí•˜ì§€ ì•Šë„ë¡ ë¶€ë“œëŸ½ê³  ì¹œê·¼í•œ í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”.
        7. ê° ì¦ìƒì´ë‚˜ ìƒíƒœë¥¼ ì„¤ëª…í•  ë•Œ ì •í™•ì„±ì„ ìœ ì§€í•˜ì„¸ìš”.
        8. ì§ˆë³‘ì˜ ì£¼ìš” íŠ¹ì§•ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ì—¬ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
        """

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful medical information translator for children."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000
        )

        return {"simplified_text": response.choices[0].message.content.strip()}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ìƒì„¸ ê°„ë‹¨í™” ì—”ë“œí¬ì¸íŠ¸
@app.post("/simplify/detailed")
async def detailed_simplify_endpoint(request: DetailedMedicalRequest):
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        ë‹¹ì‹ ì€ **ì–´ë¦°ì´ë¥¼ ìœ„í•œ ì˜í•™ ì •ë³´ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.  
        ì–´ë ¤ìš´ ì˜í•™ ì •ë³´ë¥¼ **ì‰½ê³  ì¹œì ˆí•˜ê²Œ** ì„¤ëª…í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.  
        í˜„ì¬ ì„¤ëª…í•´ì•¼ í•  ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

        [ğŸ“Œ í˜„ì¬ ì„¤ëª…í•  ì •ë³´]
        - ìœ í˜•: {request.category}
        - ëŒ€ìƒ ì—°ë ¹: {request.target_age}ì„¸
        - í˜ì´ì§€ ìœ í˜•: {request.page_type}
        - ìƒí™©: {request.situation}
        - ì›ë³¸ ì •ë³´:
          {request.original_info}

        [ğŸ“ ì„¤ëª…í•  ë•Œ ì§€ì¼œì•¼ í•  ê·œì¹™]
        1ï¸âƒ£ **{request.target_age}ì„¸ ì–´ë¦°ì´ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê³  ì¹œê·¼í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.**  
        2ï¸âƒ£ **ì–´ë ¤ìš´ ì˜í•™ ìš©ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**  
            âŒ ê¸ˆì§€ ì˜ˆì‹œ: "ì‡½ ì¦ìƒ", "ì²œì‹ë°œì‘", "í˜ˆì†ŒíŒ ê°ì†Œ", "ê°„ì†ìƒ"  
            â­• ì‰¬ìš´ í‘œí˜„ ì˜ˆì‹œ: "í”¼ë¶€ê°€ ê°€ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”.", "ë°°ê°€ ì•„í”Œ ìˆ˜ë„ ìˆì–´ìš”."  
        3ï¸âƒ£ **ì„¤ëª…ì„ ì§§ê³  ì‰½ê²Œ ì •ë¦¬í•˜ì„¸ìš”.** (í•œ ë¬¸ì¥ì€ 15ë‹¨ì–´ ì´í•˜)  
        4ï¸âƒ£ **ì–´ë¦°ì´ê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ì¹œê·¼í•œ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.**  
            ì˜ˆ) "ì´ ì•½ì€ ê°ê¸°ì— ê±¸ë ¸ì„ ë•Œ, ë”°ëœ»í•œ ì°¨ì²˜ëŸ¼ ëª¸ì„ í¸í•˜ê²Œ í•´ì¤˜ìš”."  
        5ï¸âƒ£ **ì„¤ëª…ì„ 5ê°œì˜ ë‹¨ë½ìœ¼ë¡œ ë‚˜ëˆ„ì„¸ìš”. (ê° ë‹¨ë½ì€ 2~3ë¬¸ì¥)**  
        6ï¸âƒ£ **ì•½ ì´ë¦„ì„ ì²« ë¬¸ì¥ì—ì„œ *ê¼­* (ë°˜ë“œì‹œ)) ì–¸ê¸‰í•˜ì„¸ìš”.**  
        7ï¸âƒ£ **ì–´ë¦°ì´ê°€ ë¶ˆì•ˆí•´í•˜ì§€ ì•Šë„ë¡ ë¶€ë“œëŸ¬ìš´ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.**  
        8ï¸âƒ£ **ì•½ ë³µìš© ì‹œ ì£¼ì˜ì‚¬í•­ì„ ê°•ì¡°í•˜ë˜, ë¬´ì„œìš´ í‘œí˜„ì€ í”¼í•˜ì„¸ìš”.**  
        """

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a medical expert who simplifies information for children."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000
        )

        return {"simplified_text": response.choices[0].message.content.strip()}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ìƒˆë¡œìš´ ìš”ì²­ ëª¨ë¸ ì¶”ê°€
class BasicSearchRequest(BaseModel):
    query: str

    class Config:
        json_schema_extra = {
            "example": {
                "query": "íƒ€ì´ë ˆë†€"
            }
        }

# ì•½í’ˆ ê²€ìƒ‰ (OCR ì—†ì´) ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.post("/search/drug/basic")
async def basic_drug_search_endpoint(request: BasicSearchRequest):
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ê°€ì´ì ì˜ë£Œ ê²€ìƒ‰ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.  
        ì‚¬ìš©ìê°€ íŠ¹ì • **ì˜ì•½í’ˆ** ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìœ¼ë‚˜, ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  
        ì´ì— ë”°ë¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ìœ ì‚¬í•œ ì˜ë£Œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.  

        [ğŸ“ ìš”ì²­ ì •ë³´]
        - ê²€ìƒ‰ ìœ í˜•: ì˜ì•½í’ˆ
        - ê²€ìƒ‰ì–´: "{request.query}"

        [âš ï¸ ì£¼ì˜ ì‚¬í•­]
        1ï¸âƒ£ **ê²€ìƒ‰ëœ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°**  
           - "{request.query}"ë¼ëŠ” ì •í™•í•œ ëª…ì¹­ì˜ ì˜ì•½í’ˆì´ í™•ì¸ë˜ì§€ ì•Šìœ¼ë©´ **ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤**ê³  ëª…í™•íˆ ì•ˆë‚´  
           - ìœ ì‚¬í•œ ê²€ìƒ‰ì–´ë¥¼ ì œê³µí•˜ë”ë¼ë„, **"ë‹¨, ìœ ì‚¬í•œ ì´ë¦„ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì¶”ê°€ ê²€ìƒ‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤."**ë¼ê³  ì•ˆë‚´  

        2ï¸âƒ£ **ì˜ëª»ëœ ì •ë³´ ì œê³µ ê¸ˆì§€**  
           - LLMì´ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ íŒë‹¨í•˜ë”ë¼ë„, ì—†ëŠ” ì˜ì•½í’ˆì€ **ìˆë‹¤ê³  ê°€ì •í•˜ì§€ ì•ŠìŒ**  
           - ê²€ìƒ‰ì–´ê°€ ë¶ˆëª…í™•í•  ê²½ìš°, `"ìœ ì‚¬í•œ ì˜ì•½í’ˆì´ ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë‹ˆ ì§ì ‘ ê²€ìƒ‰ì„ ì¶”ì²œí•©ë‹ˆë‹¤."`ë¼ê³  ì•ˆë‚´  

        3ï¸âƒ£ **ìœ ì‚¬ ê²€ìƒ‰ì–´ ì œê³µ ë°©ì‹**  
           - ë‹¨ìˆœíˆ ë¹„ìŠ·í•œ ë°œìŒì˜ ë‹¨ì–´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³ , **ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì˜ì•½í’ˆë§Œ ì¶”ì²œ**  
           - 5ì ì´ìƒ ì°¨ì´ë‚˜ë©´ ì¶”ì²œí•˜ì§€ ì•ŠìŒ  

        [ğŸ“Œ ì¶œë ¥ í˜•ì‹]
        ```
        â— ì°¾ìœ¼ì‹œëŠ” ì •ë³´ê°€ ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤.

        ğŸ“Œ **{request.query}ë€?**
        "{request.query}"ì´ë¼ëŠ” ì •í™•í•œ ëª…ì¹­ì˜ ì˜ì•½í’ˆì€ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        ğŸ” **ìœ ì‚¬ ê²€ìƒ‰ì–´ ì¶”ì²œ**  
        - [ì¶”ì²œ ê²€ìƒ‰ì–´ 1], [ì¶”ì²œ ê²€ìƒ‰ì–´ 2], [ì¶”ì²œ ê²€ìƒ‰ì–´ 3]
        - ë‹¨, ìœ ì‚¬í•œ ì´ë¦„ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì¶”ê°€ ê²€ìƒ‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

        ğŸ“– **ì¶”ê°€ ì •ë³´**  
        - ê²€ìƒ‰ëœ ì •ë³´ê°€ ì—†ì„ ê²½ìš°, ê´€ë ¨ëœ ë²”ì£¼ì˜ ì˜ë£Œ ì •ë³´ ì œê³µ
        ```
        """

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a medical expert providing accurate and concise medical information."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=750
        )

        return {"result": response.choices[0].message.content.strip()}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ì§ˆë³‘ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.post("/search/disease/basic")
async def basic_disease_search_endpoint(request: BasicSearchRequest):
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ê°€ì´ì ì˜ë£Œ ê²€ìƒ‰ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.  
        ì‚¬ìš©ìê°€ íŠ¹ì • **ì§ˆë³‘**ì„ ê²€ìƒ‰í–ˆìœ¼ë‚˜, ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  
        ì´ì— ë”°ë¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ìœ ì‚¬í•œ ì˜ë£Œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.  

        [ğŸ“ ìš”ì²­ ì •ë³´]
        - ê²€ìƒ‰ ìœ í˜•: ì§ˆë³‘
        - ê²€ìƒ‰ì–´: "{request.query}"

        [ğŸ“Œ ì¶œë ¥ í˜•ì‹]
        ```
        â— ì°¾ìœ¼ì‹œëŠ” ì •ë³´ê°€ ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤.

        ğŸ“Œ **{request.query}ë€?**  
        {request.query}ì€(ëŠ”) [ê°„ëµí•œ ì„¤ëª…].

        ğŸ“– **ìì„¸í•œ ì •ë³´**  
        - ì£¼ìš” ì¦ìƒ: [ì„¤ëª…]  
        - ì›ì¸: [ì„¤ëª…]  
        - ì¼ë°˜ì ì¸ ì¹˜ë£Œë²•: [ì„¤ëª…]  

        âš ï¸ **ì£¼ì˜ ì‚¬í•­**  
        - ì‘ê¸‰ ìƒí™© ì—¬ë¶€: [ì„¤ëª…]  
        - ë³‘ì› ë°©ë¬¸ì´ í•„ìš”í•œ ê²½ìš°: [ì„¤ëª…]  

        ğŸ” **ê´€ë ¨ ê²€ìƒ‰ì–´ ì¶”ì²œ**  
        - [ì¶”ì²œ ê²€ìƒ‰ì–´ 1], [ì¶”ì²œ ê²€ìƒ‰ì–´ 2], [ì¶”ì²œ ê²€ìƒ‰ì–´ 3]
        ```
        """

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a medical expert providing accurate and concise medical information."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=750
        )

        return {"result": response.choices[0].message.content.strip()}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="127.0.0.1", port=8001)
